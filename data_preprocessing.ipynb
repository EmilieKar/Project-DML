{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper notebook to unzip and create the data splits we want for our project based on the preprocessing notebook for HA1.\n",
    "\n",
    "This should be run from the same folder where the `archive.zip` file you downloaded from https://www.kaggle.com/datasets/arnaud58/landscape-pictures?resource=download is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This script assumes that you have the `archive.zip` in the same directory as this notebook\n",
    "\n",
    "zip_file = Path.cwd() / \"archive.zip\"\n",
    "if not zip_file.exists():\n",
    "    raise FileNotFoundError(\"Download and place `{}` in the current directory (`{}`)\"\n",
    "                            .format(zip_file.name, Path.cwd()))\n",
    "    \n",
    "# this doen't work as intended, needs to be added to folder named archives\n",
    "#!unzip -q archive.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd() / \"archive\"\n",
    "all_filenames = list(data_path.glob(\"*.jpg\"))\n",
    "print(f\"Found {len(all_filenames)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of the entire training dataset (20%)\n",
    "train_files, test_files = train_test_split(all_filenames, test_size=0.2, random_state=1)\n",
    "print(\"The dataset will be comprised of:\")\n",
    "print(f\"Training:\\t{len(train_files)}, Test: {len(test_files)}\")\n",
    "# print(train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and val directories and subdirectories\n",
    "subdirectories = {\"train\": train_files,\n",
    "                  \"test\": test_files,\n",
    "                 }\n",
    "\n",
    "for subdirectory in subdirectories.keys():\n",
    "    subdirectory = Path(subdirectory)\n",
    "    subdirectory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Put the training and validation data in the respective folders\n",
    "def fill_sub_dir(sub_dir, file_subset):\n",
    "    for file in file_subset:\n",
    "        file_path = Path.cwd() / sub_dir / file.name\n",
    "        os.rename(file, file_path)\n",
    "        \n",
    "for sub_dir, file_subset in subdirectories.items():\n",
    "    fill_sub_dir(sub_dir, file_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(Path.cwd() / 'archive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
